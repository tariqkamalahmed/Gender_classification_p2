{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_colwidth=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Character</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Someone had fun.</td>\n",
       "      <td>SEAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's no problem, honestly. Go on, go and open the launderette.  Leave it with me.</td>\n",
       "      <td>SHIRLEY</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last night was better than ever. What's all this?  Anything interesting?</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Have you checked the answerphone?  Any calls?</td>\n",
       "      <td>IAN</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oscar's asleep.</td>\n",
       "      <td>MAX</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>What's going on Gal? What's going on? I don't understand mate. You said you were gonna go and get her, you promised...</td>\n",
       "      <td>MINTY</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10109</th>\n",
       "      <td>Am I mad?  Have I completely lost it?</td>\n",
       "      <td>TANYA</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10110</th>\n",
       "      <td>You're late.</td>\n",
       "      <td>JACK</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10111</th>\n",
       "      <td>Ask your psycho Ex.</td>\n",
       "      <td>ROXY</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10112</th>\n",
       "      <td>She's got an evening shift but I don't want to see her again until she's sobered up.</td>\n",
       "      <td>PHIL</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                         Line  \\\n",
       "0                                                                                                            Someone had fun.   \n",
       "1                                           It's no problem, honestly. Go on, go and open the launderette.  Leave it with me.   \n",
       "2                                                    Last night was better than ever. What's all this?  Anything interesting?   \n",
       "3                                                                               Have you checked the answerphone?  Any calls?   \n",
       "4                                                                                                             Oscar's asleep.   \n",
       "...                                                                                                                       ...   \n",
       "10108  What's going on Gal? What's going on? I don't understand mate. You said you were gonna go and get her, you promised...   \n",
       "10109                                                                                   Am I mad?  Have I completely lost it?   \n",
       "10110                                                                                                            You're late.   \n",
       "10111                                                                                                     Ask your psycho Ex.   \n",
       "10112                                    She's got an evening shift but I don't want to see her again until she's sobered up.   \n",
       "\n",
       "      Character  Gender  \n",
       "0          SEAN    male  \n",
       "1       SHIRLEY  female  \n",
       "2           MAX    male  \n",
       "3           IAN    male  \n",
       "4           MAX    male  \n",
       "...         ...     ...  \n",
       "10108     MINTY    male  \n",
       "10109     TANYA  female  \n",
       "10110      JACK    male  \n",
       "10111      ROXY  female  \n",
       "10112      PHIL    male  \n",
       "\n",
       "[10113 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in training data and display in pandas dataframe\n",
    "train_path='training.csv'\n",
    "all_train_data = pd.read_csv(train_path, skip_blank_lines = True, header=None, names=['Line','Character','Gender'])\n",
    "test_path ='test.csv'\n",
    "test_data = pd.read_csv(test_path, skip_blank_lines = True, header=None, names=['Line','Character','Gender'])\n",
    "\n",
    "# Inspect\n",
    "all_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:  (10113, 3)\n",
      "Train set:  (9101, 3)\n",
      "Validation set:  (1012, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test data for heldout validation with random samples of 9:1 train/heldout split\n",
    "print('Raw Data: ',np.shape(all_train_data))\n",
    "idx = int(0.9 * np.shape(all_train_data)[0])\n",
    "train_data = all_train_data[:idx]\n",
    "val_data = all_train_data[idx:]\n",
    "print('Train set: ',np.shape(train_data))\n",
    "print('Validation set: ',np.shape(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one document per character\n",
    "def create_character_document_from_dataframe(df, max_line_count):\n",
    "    \"\"\"Returns a dict with the name of the character as key,\n",
    "    their lines joined together as a single string, with end of line _EOL_\n",
    "    markers between them.\n",
    "    \n",
    "    ::max_line_count:: the maximum number of lines to be added per character\n",
    "    \"\"\"\n",
    "    character_docs = {}\n",
    "    character_line_count = {}\n",
    "    for line, name, gender in zip(df.Line, df.Character, df.Gender):\n",
    "        if not name in character_docs.keys():\n",
    "            character_docs[name] = \"\"\n",
    "            character_line_count[name] = 0\n",
    "        if character_line_count[name]==max_line_count:\n",
    "            continue\n",
    "        character_docs[name] += str(line)   + \" _EOL_ \"  # adding an end-of-line token\n",
    "        character_line_count[name]+=1\n",
    "    print(\"lines per character\", character_line_count)\n",
    "    return character_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines per character {'SEAN': 360, 'SHIRLEY': 360, 'MAX': 360, 'IAN': 360, 'MINTY': 360, 'RONNIE': 360, 'STACEY': 360, 'JANE': 360, 'PHIL': 360, 'CLARE': 359, 'TANYA': 360, 'HEATHER': 360, 'GARRY': 308, 'BRADLEY': 292, 'CHRISTIAN': 357, 'STEVEN': 268, 'ROXY': 360, 'JACK': 360}\n",
      "Num. Characters:  18 \n",
      "\n",
      "SEAN Number of Words:  3629\n",
      "SHIRLEY Number of Words:  4023\n",
      "MAX Number of Words:  4627\n",
      "IAN Number of Words:  4165\n",
      "MINTY Number of Words:  3914\n",
      "RONNIE Number of Words:  3528\n",
      "STACEY Number of Words:  3979\n",
      "JANE Number of Words:  3818\n",
      "PHIL Number of Words:  3950\n",
      "CLARE Number of Words:  4311\n",
      "TANYA Number of Words:  4092\n",
      "HEATHER Number of Words:  4040\n",
      "GARRY Number of Words:  3599\n",
      "BRADLEY Number of Words:  2865\n",
      "CHRISTIAN Number of Words:  3979\n",
      "STEVEN Number of Words:  2485\n",
      "ROXY Number of Words:  3824\n",
      "JACK Number of Words:  4110\n",
      "total words 68938\n"
     ]
    }
   ],
   "source": [
    "# print out the number of words each character has in the training set\n",
    "# only use the first 360 lines of each character\n",
    "train_character_docs = create_character_document_from_dataframe(train_data, max_line_count=360)\n",
    "print('Num. Characters: ',len(train_character_docs.keys()),\"\\n\")\n",
    "total_words = 0\n",
    "for name in train_character_docs.keys():\n",
    "    print(name, 'Number of Words: ',len(train_character_docs[name].split()))\n",
    "    total_words += len(train_character_docs[name].split())\n",
    "print(\"total words\", total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def pre_process(character_text):\n",
    "    pos_tags = [x[1] for x in pos_tag(character_text)] \n",
    "    text = word_tokenize(character_text)\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(character_text)\n",
    "    \n",
    "    tokens = [t.lower() for t in tokens]\n",
    "\n",
    "    stop = set(stopwords.words('english'))\n",
    "    tokens = [t for t in tokens if t not in stop]\n",
    "    \n",
    "#     lemmatiser = WordNetLemmatizer()\n",
    "#     tokens = [lemmatiser.lemmatize(t) for t in tokens]\n",
    "        \n",
    "#     p_stemmer = PorterStemmer()\n",
    "#     tok = []\n",
    "#     for t in tokens:\n",
    "#         tok.append(p_stemmer.stem(t))\n",
    "#     tokens = tok\n",
    "        \n",
    "    tokens = [t for t in tokens if t] # ensure no empty space\n",
    "    \n",
    "    \n",
    "    return tokens,pos_tags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for Q1 -Improving pre-processing, used same tec\n",
    "\n",
    "no pre_processing feature removed -token,lower,stop words,lemma,stemmer,pos_tags\n",
    "\n",
    "mean rank 1.3333333333333333\n",
    "mean cosine similarity 0.9449373806554598\n",
    "14 correct out of 18 / accuracy: 0.7777777777777778\n",
    "\n",
    "Removing stemmers like in assignment 3\n",
    "\n",
    "mean rank 1.2777777777777777\n",
    "mean cosine similarity 0.9452568423388629\n",
    "14 correct out of 18 / accuracy: 0.7777777777777778\n",
    "\n",
    "Removing lemmas like in assignment 3\n",
    "\n",
    "mean rank 1.3333333333333333\n",
    "mean cosine similarity 0.944883026696097\n",
    "14 correct out of 18 / accuracy: 0.7777777777777778\n",
    "\n",
    "Removing lemmas and stemmers like in assignment 3\n",
    "\n",
    "mean rank 1.3333333333333333\n",
    "mean cosine similarity 0.9451552502764261\n",
    "14 correct out of 18 / accuracy: 0.7777777777777778\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of pairs of (character name, pre-processed character) \n",
    "training_corpus = [(name, pre_process(doc)) for name, doc in sorted(train_character_docs.items())]\n",
    "train_labels = [name for name, doc in training_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature_vector_dictionary(put,extra_features=[]):\n",
    "    character_doc,pos_tags=put\n",
    "    \"\"\"Converts a list of pre-processed tokens and extra features\n",
    "    to a Dictionary as a function of the tokens.\n",
    "    \n",
    "    Initially just a simple count. Improve this for Q2.\n",
    "    \n",
    "    ::character_doc:: a list of pre-processed tokens\n",
    "    ::extra_features:: any extra features for the character to be added to feature vector dict\n",
    "    \"\"\"\n",
    "    \n",
    "    counts = Counter(character_doc)  # for now a simple count\n",
    "    counts = dict(counts)\n",
    "    featureVector = {}\n",
    "\n",
    "    for tokens in character_doc:\n",
    "        try:\n",
    "            featureVector[tokens] += 1.0\n",
    "        except KeyError:\n",
    "            featureVector[tokens] = 1.0\n",
    "\n",
    "            \n",
    "\n",
    "    for pos in pos_tags: #split words into tokens and pos found to be worse by itself but no effect when using with weighting \n",
    "        if pos not in character_doc:\n",
    "            featureVector[pos] = 1.0\n",
    "        else:\n",
    "            featureVector[pos] = float(featureVector[pos] + 1)\n",
    "            \n",
    "     \n",
    "    for i in range(1, len(character_doc)): #found to improve the score 1.333 to 1.1666 with both pos_tags and weighting used\n",
    "            bigram = character_doc[i-1] + \" \" + character_doc[i]\n",
    "            try:\n",
    "                featureVector[bigram] += 1.0/len(character_doc)\n",
    "            except KeyError:\n",
    "                featureVector[bigram] = 1.0/len(character_doc)\n",
    "            try:\n",
    "                featureVector[bigram] += 1.0\n",
    "            except KeyError:\n",
    "                featureVector[bigram] = 1.0\n",
    "\n",
    "#     for i in range(1, len(character_doc)): #found to reduce the score 1.1666 to 1.333 with both pos_tags, weighting used and bigrams\n",
    "#             trigram = character_doc[i-2] + \" \" + character_doc[i]\n",
    "#             try:\n",
    "#                 featureVector[trigram] += 1.0/len(character_doc)\n",
    "#             except KeyError:\n",
    "#                 featureVector[trigram] = 1.0/len(character_doc)\n",
    "#             try:\n",
    "#                 featureVector[trigram] += 1.0\n",
    "#             except KeyError:\n",
    "#                 featureVector[trigram] = 1.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return featureVector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for Q2\n",
    "found after commenting out lemmas and stemmers, weighting using tokens by itself \n",
    "\n",
    "mean rank 1.3333333333333333\n",
    "mean cosine similarity 0.9451552502764261\n",
    "14 correct out of 18 / accuracy: 0.7777777777777778\n",
    "    \n",
    "Pos_tags by itself\n",
    "\n",
    "mean rank 10.0\n",
    "mean cosine similarity 0.9381300979996089\n",
    "1 correct out of 18 / accuracy: 0.05555555555555555\n",
    "\n",
    "Bigrams by itself\n",
    "\n",
    "mean rank 3.1666666666666665\n",
    "mean cosine similarity 0.3377137806067232\n",
    "10 correct out of 18 / accuracy: 0.5555555555555556\n",
    "\n",
    "Weight using tokens and bigrams\n",
    "\n",
    "mean rank 1.2222222222222223\n",
    "mean cosine similarity 0.9155221925839011\n",
    "14 correct out of 18 / accuracy: 0.7777777777777778\n",
    "\n",
    "Weight using tokens,bigrams and pos_tags\n",
    "\n",
    "mean rank 1.1666666666666667\n",
    "mean cosine similarity 0.9113816376825312\n",
    "15 correct out of 18 / accuracy: 0.8333333333333334\n",
    "\n",
    "Weight using tokens,bigrams,trigrams and pos_tags\n",
    "\n",
    "mean rank 1.3333333333333333\n",
    "mean cosine similarity 0.8855689327647407\n",
    "13 correct out of 18 / accuracy: 0.7222222222222222\n",
    "\n",
    "\n",
    "Weight using tokens and bigrams with only stemmers removed\n",
    "\n",
    "mean rank 1.3333333333333333\n",
    "mean cosine similarity 0.9403147409804065\n",
    "14 correct out of 18 / accuracy: 0.7777777777777778\n",
    "\n",
    "\n",
    "Weight using tokens,bigrams and pos_tags with only stemmers removed\n",
    "\n",
    "mean rank 1.3888888888888888\n",
    "mean cosine similarity 0.9096986847698092\n",
    "13 correct out of 18 / accuracy: 0.7222222222222222\n",
    "\n",
    "Results show best combination is using weight using tokens,bigrams and pos_tags with both lemmas and stemmers removed, even though in preprocessing it was found that removing only stemmers gave the best results when only testing using the weights of the token as the feature.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpusVectorizer = DictVectorizer()   # corpusVectorizor which will just produce sparse vectors from feature dicts\n",
    "\n",
    "\n",
    "# def create_document_matrix_from_corpus(corpus, fitting=False):\n",
    "    \n",
    "#     # uses the global variable of the corpus Vectorizer to improve things\n",
    "#     if fitting:\n",
    "#                 corpusVectorizer.fit([to_feature_vector_dictionary(doc) for name, doc in corpus])\n",
    "#     doc_feature_matrix = corpusVectorizer.transform([to_feature_vector_dictionary(doc) for name, doc in corpus])\n",
    "\n",
    "    \n",
    "#     #training_feature_matrix[0].toarray()\n",
    "#     return doc_feature_matrix\n",
    "\n",
    "# training_feature_matrix = create_document_matrix_from_corpus(training_corpus, fitting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "corpusVectorizer = DictVectorizer()   # corpusVectorizor which will just produce sparse vectors from feature dicts\n",
    "# Any matrix transformers (e.g. tf-idf transformers) should be initialized here\n",
    "tf_id = TfidfTransformer()  \n",
    "Kbest = SelectKBest(chi2,k=500)  \n",
    "\n",
    "\n",
    "\n",
    "def create_document_matrix_from_corpus(corpus, fitting=False):\n",
    "    \"\"\"Method which fits different vectorizers\n",
    "    on data and returns a matrix.\n",
    "    \n",
    "    Currently just does simple conversion to matrix by vectorizing the dictionary. Improve this for Q3.\n",
    "    \n",
    "    ::corpus:: a list of (class_label, document) pairs.\n",
    "    ::fitting:: a boolean indicating whether to fit/train the vectorizers (should be true on training data)\n",
    "    \"\"\"\n",
    "    \n",
    "    # uses the global variable of the corpus Vectorizer to improve things\n",
    "    if fitting:\n",
    "                corpusVectorizer.fit([to_feature_vector_dictionary(doc) for name, doc in corpus])\n",
    "    doc_feature_matrix = corpusVectorizer.transform([to_feature_vector_dictionary(doc) for name, doc in corpus])\n",
    "    doc_feature_matrix=tf_id.fit_transform(doc_feature_matrix)\n",
    "#     doc_feature_matrix=Kbest.fit_transform(doc_feature_matrix,train_labels)\n",
    "        \n",
    "    if fitting == False:\n",
    "        doc_feature_matrix =corpusVectorizer.transform([to_feature_vector_dictionary(doc) for name, doc in corpus])\n",
    "        doc_feature_matrix=tf_id.transform(doc_feature_matrix)\n",
    "#         doc_feature_matrix=Kbest.transform(doc_feature_matrix)\n",
    "        \n",
    "    #training_feature_matrix[0].toarray()\n",
    "    return doc_feature_matrix\n",
    "\n",
    "training_feature_matrix = create_document_matrix_from_corpus(training_corpus, fitting=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for Q3\n",
    "Using Tfidf and select K best were found to be worse performing than using just corpusVectorizer. Results were found using the best scoring combinations from previous questions.\n",
    "\n",
    "\n",
    "Tfidf \n",
    "\n",
    "mean rank 1.1111111111111112\n",
    "mean cosine similarity 0.6681151005424001\n",
    "16 correct out of 18 / accuracy: 0.8888888888888888\n",
    "\n",
    "Kbest set to 4520\n",
    "\n",
    "mean rank 9.38888888888889\n",
    "mean cosine similarity 0.013130738137719068\n",
    "1 correct out of 18 / accuracy: 0.05555555555555555\n",
    "\n",
    "Kbest set to 2000\n",
    "\n",
    "mean rank 7.722222222222222\n",
    "mean cosine similarity 0.030052353261394722\n",
    "1 correct out of 18 / accuracy: 0.05555555555555555\n",
    "\n",
    "Kbest set to 1000\n",
    "\n",
    "mean rank 9.944444444444445\n",
    "mean cosine similarity 0.056850030367150466\n",
    "1 correct out of 18 / accuracy: 0.05555555555555555\n",
    "\n",
    "Kbest set to 500\n",
    "mean rank 8.722222222222221\n",
    "mean cosine similarity 0.0774764423362279\n",
    "1 correct out of 18 / accuracy: 0.05555555555555555\n",
    "\n",
    "Tfidf and kbest set to 4520\n",
    "\n",
    "mean rank 9.38888888888889\n",
    "mean cosine similarity 0.038613284637541934\n",
    "0 correct out of 18 / accuracy: 0.0\n",
    "\n",
    "Tfidf and kbest set to 2000\n",
    "\n",
    "mean rank 10.277777777777779\n",
    "mean cosine similarity 0.05195866159935372\n",
    "0 correct out of 18 / accuracy: 0.0\n",
    "\n",
    "Tfidf and kbest set to 1000\n",
    "\n",
    "mean rank 9.944444444444445\n",
    "mean cosine similarity 0.056850030367150466\n",
    "1 correct out of 18 / accuracy: 0.05555555555555555\n",
    "\n",
    "\n",
    "Tfidf and kbest set to 500\n",
    "\n",
    "mean rank 8.88888888888889\n",
    "mean cosine similarity 0.06696320374594956\n",
    "1 correct out of 18 / accuracy: 0.05555555555555555\n",
    "\n",
    "corpusVectorizer\n",
    "\n",
    "mean rank 1.1666666666666667\n",
    "mean cosine similarity 0.9113816376825312\n",
    "15 correct out of 18 / accuracy: 0.8333333333333334\n",
    "\n",
    "\n",
    "Best results was just using the Tfidftransformer using Kbest doesnt seem to produce the great results. Also using Tfidftransformer was gave a slighlty better result than using just the corpusVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18x25988 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41737 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines per character {'IAN': 40, 'STACEY': 40, 'JANE': 40, 'SEAN': 40, 'CLARE': 40, 'MAX': 40, 'TANYA': 40, 'JACK': 40, 'SHIRLEY': 40, 'RONNIE': 40, 'MINTY': 39, 'GARRY': 32, 'STEVEN': 30, 'BRADLEY': 40, 'ROXY': 40, 'CHRISTIAN': 40, 'HEATHER': 40, 'PHIL': 40}\n",
      "Num. Characters:  18 \n",
      "\n",
      "IAN Num of Words:  611\n",
      "STACEY Num of Words:  409\n",
      "JANE Num of Words:  503\n",
      "SEAN Num of Words:  414\n",
      "CLARE Num of Words:  512\n",
      "MAX Num of Words:  411\n",
      "TANYA Num of Words:  399\n",
      "JACK Num of Words:  434\n",
      "SHIRLEY Num of Words:  419\n",
      "RONNIE Num of Words:  362\n",
      "MINTY Num of Words:  555\n",
      "GARRY Num of Words:  387\n",
      "STEVEN Num of Words:  312\n",
      "BRADLEY Num of Words:  509\n",
      "ROXY Num of Words:  376\n",
      "CHRISTIAN Num of Words:  517\n",
      "HEATHER Num of Words:  543\n",
      "PHIL Num of Words:  411\n",
      "total words 8084\n"
     ]
    }
   ],
   "source": [
    "# get the validation data- only 40 lines used for each character\n",
    "val_character_docs = create_character_document_from_dataframe(val_data, max_line_count=40)\n",
    "print('Num. Characters: ',len(val_character_docs.keys()),\"\\n\")\n",
    "total_words = 0\n",
    "for name in val_character_docs.keys():\n",
    "    print(name, 'Num of Words: ',len(val_character_docs[name].split()))\n",
    "    total_words += len(val_character_docs[name].split())\n",
    "print(\"total words\", total_words)\n",
    "\n",
    "# create list of pairs of (character name, pre-processed character) \n",
    "val_corpus = [(name, pre_process(doc)) for name, doc in sorted(val_character_docs.items())]\n",
    "val_labels = [name for name, doc in val_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just transform the val_feature_matrix, don't fit\n",
    "val_feature_matrix = create_document_matrix_from_corpus(val_corpus, fitting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18x25988 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4341 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(v1, v2):\n",
    "    \"\"\"Takes a pair of vectors v1 and v2 (1-d arrays e.g. [0, 0.5, 0.5])\n",
    "    returns the cosine similarity between the vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute cosine similarity manually\n",
    "    manual_cosine_similarity = np.dot(v1, v2)  /(norm(v1) * norm(v2))\n",
    "    \n",
    "    return manual_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IR_evaluation_scores(train_feature_matrix, test_feature_matrix, train_labels, test_labels):\n",
    "    \"\"\"\n",
    "    Computes an information retrieval based on training data feature matrix and test data feature matrix\n",
    "    returns 4-tuple:\n",
    "    ::mean_rank:: mean of the ranking of the target document in terms of similarity to the query/test document\n",
    "    1 is the best possible score.\n",
    "    ::mean_cosine_similarity:: mean cosine similarity score for the target document vs. the test document of the same class\n",
    "    ::accuracy:: proportion of test documents correctly classified\n",
    "    ::df:: a data frame with all the similarity measures of the test documents vs. train documents\n",
    "    \n",
    "    params:\n",
    "    ::train_feature_matrix:: a numpy matrix N x M shape where N = number of characters M = number of features\n",
    "    ::test_feature_matrix::  a numpy matrix N x M shape where N = number of characters M = number of features\n",
    "    ::train_labels:: a list of character names for the training data in order consistent with train_feature_matrix\n",
    "    ::test_labels:: a list of character names for the test data in order consistent with test_feature_matrix\n",
    "    \"\"\"\n",
    "    rankings = []\n",
    "    all_cosine_similarities = []\n",
    "    pairwise_cosine_similarity = []\n",
    "    pairs = []\n",
    "    correct = 0\n",
    "    for i, target in enumerate(test_labels):\n",
    "        # compare the left out character against the mean\n",
    "        idx = i \n",
    "        fm_1 = test_feature_matrix.toarray()[idx]\n",
    "        all_sims = {}\n",
    "        # print(\"target:\", target)\n",
    "        for j, other in enumerate(train_labels):\n",
    "            fm_2 = train_feature_matrix.toarray()[j]\n",
    "            manual_cosine_similarity = compute_cosine_similarity(fm_1, fm_2)\n",
    "            pairs.append((target, other))\n",
    "            pairwise_cosine_similarity.append(manual_cosine_similarity)\n",
    "            if other == target:\n",
    "                all_cosine_similarities.append(manual_cosine_similarity)\n",
    "            all_sims[other] = manual_cosine_similarity\n",
    "\n",
    "            # print(target, other, manual_cosine_similarity)\n",
    "        sorted_similarities = sorted(all_sims.items(),key=lambda x:x[1],reverse=True)\n",
    "        # print(sorted_similarities)\n",
    "        ranking = {key[0]: rank for rank, key in enumerate(sorted_similarities, 1)}\n",
    "        # print(\"Ranking for target\", ranking[target])\n",
    "        if ranking[target] == 1:\n",
    "            correct += 1\n",
    "        rankings.append(ranking[target])\n",
    "        # print(\"*****\")\n",
    "    mean_rank = np.mean(rankings)\n",
    "    mean_cosine_similarity = np.mean(all_cosine_similarities)\n",
    "    accuracy = correct/len(test_labels)\n",
    "    print(\"mean rank\", np.mean(rankings))\n",
    "    print(\"mean cosine similarity\", mean_cosine_similarity)\n",
    "    print(correct, \"correct out of\", len(test_labels), \"/ accuracy:\", accuracy )\n",
    "    \n",
    "    # get a dafaframe showing all the similarity scores of training vs test docs\n",
    "    df = pd.DataFrame({'doc1': [x[0] for x in pairs], 'doc2': [x[1] for x in pairs],\n",
    "                       'similarity': pairwise_cosine_similarity})\n",
    "\n",
    "    # display characters which are most similar and least similar\n",
    "    df.loc[[df.similarity.values.argmax(), df.similarity.values.argmin()]]\n",
    "    return (mean_rank, mean_cosine_similarity, accuracy, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heat_map_similarity(df):\n",
    "    \"\"\"Takes a dataframe with header 'doc1, doc2, similarity'\n",
    "    Plots a heatmap based on the similarity scores.\n",
    "    \"\"\"\n",
    "    test_labels =  sorted(list(set(df.sort_values(['doc1'])['doc1'])))\n",
    "    # add padding 1.0 values to either side\n",
    "    cm = [[1.0,] * (len(test_labels)+2)]\n",
    "    for target in test_labels:\n",
    "        new_row = [1.0]\n",
    "        for x in df.sort_values(['doc1', 'doc2'])[df['doc1']==target]['similarity']:\n",
    "            new_row.append(x)\n",
    "        new_row.append(1.0)\n",
    "        cm.append(new_row)\n",
    "    cm.append([1.0,] * (len(test_labels)+2))\n",
    "    #print(cm)\n",
    "    labels = [\"\"] + test_labels + [\"\"]\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm)\n",
    "    plt.title('Similarity matrix between documents as vectors')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels( labels, rotation=45)\n",
    "    ax.set_yticklabels( labels)\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        for j in range(len(cm)):\n",
    "\n",
    "            text = ax.text(j, i, round(cm[i][j],3),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.xlabel('Training Vector Doc')\n",
    "    plt.ylabel('Test Vector Doc')\n",
    "    #fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rank 1.1111111111111112\n",
      "mean cosine similarity 0.6681151005424001\n",
      "16 correct out of 18 / accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "mean_rank, mean_cosine_simliarity, acc, df = compute_IR_evaluation_scores(training_feature_matrix, val_feature_matrix, train_labels, val_labels)\n",
    "# plot_heat_map_similarity(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines per character {'SEAN': 400, 'SHIRLEY': 400, 'MAX': 400, 'IAN': 400, 'MINTY': 400, 'RONNIE': 400, 'STACEY': 400, 'JANE': 400, 'PHIL': 400, 'CLARE': 400, 'TANYA': 400, 'HEATHER': 400, 'GARRY': 340, 'BRADLEY': 332, 'CHRISTIAN': 397, 'STEVEN': 298, 'ROXY': 400, 'JACK': 400}\n",
      "Num. Characters:  18 \n",
      "\n",
      "SEAN Number of Words:  3949\n",
      "SHIRLEY Number of Words:  4427\n",
      "MAX Number of Words:  5098\n",
      "IAN Number of Words:  4730\n",
      "MINTY Number of Words:  4374\n",
      "RONNIE Number of Words:  3903\n",
      "STACEY Number of Words:  4370\n",
      "JANE Number of Words:  4154\n",
      "PHIL Number of Words:  4322\n",
      "CLARE Number of Words:  4837\n",
      "TANYA Number of Words:  4605\n",
      "HEATHER Number of Words:  4484\n",
      "GARRY Number of Words:  3986\n",
      "BRADLEY Number of Words:  3374\n",
      "CHRISTIAN Number of Words:  4496\n",
      "STEVEN Number of Words:  2797\n",
      "ROXY Number of Words:  4196\n",
      "JACK Number of Words:  4564\n",
      "total words 76666\n",
      "lines per character {'STACEY': 40, 'RONNIE': 40, 'STEVEN': 37, 'TANYA': 40, 'MAX': 40, 'ROXY': 40, 'IAN': 40, 'JANE': 40, 'JACK': 40, 'CLARE': 31, 'PHIL': 40, 'GARRY': 40, 'SHIRLEY': 40, 'CHRISTIAN': 40, 'BRADLEY': 40, 'HEATHER': 40, 'SEAN': 40, 'MINTY': 40}\n",
      "Num. Characters:  18 \n",
      "\n",
      "STACEY Number of Words:  461\n",
      "RONNIE Number of Words:  416\n",
      "STEVEN Number of Words:  372\n",
      "TANYA Number of Words:  451\n",
      "MAX Number of Words:  510\n",
      "ROXY Number of Words:  401\n",
      "IAN Number of Words:  415\n",
      "JANE Number of Words:  422\n",
      "JACK Number of Words:  399\n",
      "CLARE Number of Words:  306\n",
      "PHIL Number of Words:  413\n",
      "GARRY Number of Words:  477\n",
      "SHIRLEY Number of Words:  315\n",
      "CHRISTIAN Number of Words:  453\n",
      "BRADLEY Number of Words:  520\n",
      "HEATHER Number of Words:  457\n",
      "SEAN Number of Words:  363\n",
      "MINTY Number of Words:  431\n",
      "total words 7582\n",
      "mean rank 1.1111111111111112\n",
      "mean cosine similarity 0.6808918013838048\n",
      "17 correct out of 18 / accuracy: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# redo on all training data with the first 400 character lines used\n",
    "train_character_docs = create_character_document_from_dataframe(all_train_data, max_line_count=400)\n",
    "print('Num. Characters: ',len(train_character_docs.keys()),\"\\n\")\n",
    "total_words = 0\n",
    "for name in train_character_docs.keys():\n",
    "    print(name, 'Number of Words: ',len(train_character_docs[name].split()))\n",
    "    total_words += len(train_character_docs[name].split())\n",
    "print(\"total words\", total_words)\n",
    "\n",
    "training_corpus = [(name, pre_process(doc)) for name, doc in train_character_docs.items()]\n",
    "train_labels = [name for name, doc in training_corpus]\n",
    "\n",
    "corpusVectorizer = DictVectorizer()   # initialize a corpusVectorizor which will output sparse vectors from dicts\n",
    "# Any matrix transformers (e.g. tf-idf transformers) should be initialized here\n",
    "\n",
    "\n",
    "training_feature_matrix = create_document_matrix_from_corpus(training_corpus, fitting=True)\n",
    "\n",
    "# get the test data using 40 lines per character\n",
    "test_character_docs = create_character_document_from_dataframe(test_data, max_line_count=40)\n",
    "print('Num. Characters: ',len(test_character_docs.keys()),\"\\n\")\n",
    "total_words = 0\n",
    "for name in test_character_docs.keys():\n",
    "    print(name, 'Number of Words: ',len(test_character_docs[name].split()))\n",
    "    total_words += len(test_character_docs[name].split())\n",
    "print(\"total words\", total_words)\n",
    "\n",
    "# create list of pairs of (character name, pre-processed character) \n",
    "test_corpus = [(name, pre_process(doc)) for name, doc in test_character_docs.items()]\n",
    "test_labels = [name for name, doc in test_corpus]\n",
    "\n",
    "\n",
    "# Just transform the val_feature_matrix, don't fit\n",
    "test_feature_matrix = create_document_matrix_from_corpus(test_corpus, fitting=False)\n",
    "\n",
    "\n",
    "mean_rank, mean_cosine_simliarity, acc, df = compute_IR_evaluation_scores(training_feature_matrix, test_feature_matrix, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
